#!/usr/bin/env bash
# Update ubuntu, install chromiun libraries, install node
sudo apt-get update -y
sudo apt-get install ca-certificates fonts-liberation gconf-service libappindicator1 libasound2 libatk-bridge2.0-0 libatk1.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgbm1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 libnss3 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 lsb-release wget xdg-utils -y
sudo curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -
sudo apt-get install -y nodejs

# Download repo
sudo git clone https://github.com/sebas119/job_email_scrapper.git
cd job_email_scrapper
sudo git checkout develop

# Install the libraries need for the emailscrapper
sudo npm install

# Install nginx and config it
sudo apt-get -y install nginx
sudo echo -e "server{\n\tlisten 80 default_server;\n\tlisten [::]:80 default_server ipv6only=on;\n\tserver_name localhost;\n\tlocation / {\n\t\tproxy_pass http://127.0.0.1:3000;\n\t}\n\tlocation ~ /api/(.*)$ {\n\t\tproxy_pass http://127.0.0.1:4000;\n\t}\n}" > /etc/nginx/sites-available/default
sudo service nginx restart

# Config the scrapper cron job
sudo echo "0 */6 * * * node /root/job_email_scrapper/app.js >> /root/file.log" >> /var/spool/cron/crontabs/root
sudo EDITOR=vim.basic crontab /var/spool/cron/crontabs/root
sudo cron

# Up the project
sudo sed -i "s/localhost:4000/$(hostname).19.hbtn-cod.io/g" pages/index.js
sudo nohup node app.js >> /root/fileScrapper.log &
sudo nohup node server.js >> /root/fileServer.log &
sudo nohup npm run next >> /root/fileNext.log &